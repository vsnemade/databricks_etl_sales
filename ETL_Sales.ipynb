# Set your access key config
spark.conf.set(
    "fs.azure.account.key.stgdatalakedemo.dfs.core.windows.net",
    "cHDAU95MEKkZvkiAJJw4Ncm65tdk9MtTF+THak6ujkf70uIila1oqWB3B6M+sYA4ZtKr/kXmwXDF+AStF/XFCA=="
)

# Read from ADLS Gen2
df = spark.read.option("header", True).csv("abfss://rawdata@stgdatalakedemo.dfs.core.windows.net/sales_data.csv")
df.show()

electronics_df = df.filter(df.Category == "Electronics")
electronics_df.show()
electronics_df.write.mode("overwrite").parquet("abfss://rawdata@stgdatalakedemo.dfs.core.windows.net/processeddata/electronics")

df_parquet = spark.read.parquet("abfss://rawdata@stgdatalakedemo.dfs.core.windows.net/processeddata/electronics")
df_parquet.createOrReplaceTempView("electronics_sales")

result = spark.sql("SELECT Customer, Amount FROM electronics_sales WHERE Amount > 1500")
result.show()
